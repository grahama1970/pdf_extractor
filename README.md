# PDF Extraction Service üìÑüîçü§ù

## Overview üåü

The `pdf-extraction-service` is a Dockerized application designed to extract structured data (tables, headings, paragraphs) from PDF documents, with support for a Human-in-the-Loop (HITL) workflow for validating and refining extractions. It combines automated table extraction using Camelot, Marker, and Qwen-VL-2B with optional human validation via Label Studio, enabling precise table identification and processing for scientific PDFs.

The service uses a **FastAPI server** (`api.py`) for Dockerized deployment, supporting asynchronous PDF processing and real-time updates via Server-Sent Events (SSE) for compatibility with Multi-Cloud Platform (MCP) architectures. A **Typer CLI** (`cli.py`) provides a local deployment option, mirroring the API's core conversion functionality. The core extraction logic is handled by `pdf_converter.py`, which integrates Camelot, Marker, and Qwen-VL-2B for robust PDF processing.

This project is built to handle complex PDF layouts, including scanned documents and multi-page tables, and is designed for agentic workflows where AI-driven extraction can be refined by human expertise.

## Complete Extraction Pipeline

The pdf_extractor implements a structured pipeline:

1. **PDF Loading**: Read PDF document into memory
2. **Content Extraction**: Extract using a layered approach:
   - Marker-based extraction for primary content
   - Camelot for table detection
   - Qwen VL-2B for complex visual elements
3. **Conversion to Markdown**: Structure content in markdown format
4. **JSON Conversion**: Convert to ordered JSON objects
5. **Section Hierarchy Management**: Maintain document structure
6. **ArangoDB Storage**: Insert JSON objects into ArangoDB
7. **Query Interface**: Enable filtered content queries from ArangoDB

## Processing Characteristics

- **Computational Requirements**: Processing is resource-intensive
  - Expected runtime: Minutes per document
  - System requirements: 256GB RAM, 24GB GPU
  - Optimization for speed is not required given hardware

- **Error Handling Strategy**:
  - Log errors but continue processing
  - Skip elements that can't be processed
  - Robustness is prioritized over completeness

## ‚ú® Features

- ‚úÖ **Multi-Method Table Extraction**: Extracts tables using Camelot (text-based PDFs), Marker (Markdown-based), and Qwen-VL-2B (scanned PDFs). (Handled by `pdf_converter.py`)
- ‚úÖ **Human-in-the-Loop Validation**: Supports validation via Label Studio for ground truth accuracy. (Optional, requires extending `api.py`)
- ‚úÖ **Hierarchical JSON Output**: Produces `structured.json` with tables, headings, and paragraphs, including metadata (e.g., page_range, source). (Generated by `pdf_converter.py`)
- ‚úÖ **Clean-Text Normalization**: Normalizes text using `cleantext` for consistency. (Handled by `pdf_converter.py`)
- ‚úÖ **Scanned PDF Support**: Falls back to Qwen-VL-2B for OCR-based extraction on scanned documents. (Handled by `pdf_converter.py`)
- ‚úÖ **Asynchronous API with SSE**: FastAPI server (`api.py`) handles PDF uploads and streams conversion progress via SSE, ideal for MCP architectures.
- ‚úÖ **Local CLI**: Typer CLI (`cli.py`) enables local PDF-to-JSON conversion without a server.
- ‚úÖ **Label Studio Integration**: Optional integration for task generation and corrections (requires additional endpoints in `api.py`). (Configured via `labeling_config.xml`)
- ‚úÖ **Dockerized Deployment**: Uses Docker Compose with services for FastAPI and Label Studio, with shared volumes for persistence. (Defined in `docker-compose.yml`)
- ‚úÖ **Modular Architecture**: Separates extraction logic (`pdf_converter.py`), API (`api.py`), CLI (`cli.py`), and annotation (Label Studio) for maintainability.
- ‚úÖ **Logging and Monitoring**: Uses `loguru` for detailed logging of extraction and API events.
- ‚úÖ **Scalability**: Optimized for high-confidence extractions, with batch processing support.
- ‚úÖ **ArangoDB Integration**: Stores extracted JSON documents with support for semantic, BM25, keyword, and hybrid queries.

## üèóÔ∏è Runtime Architecture Diagram

```mermaid
graph TD
    subgraph "External Client (e.g., AI Agent or User)"
        Client -- "1. POST /convert\n(PDF file)" --> FastAPI
        ClientResp1 -- "2. JSON {data}" --> Client
        Client -- "3. POST /stream/convert\n(PDF file)" --> FastAPI
        ClientResp2 -- "4. SSE Stream {progress, data}" --> Client
        Client -- "5. GET /status" --> FastAPI
        ClientResp3 -- "6. JSON {status}" --> Client
        Client -- "7. CLI: convert\n(sample.pdf)" --> CLI
        ClientResp4 -- "8. JSON file\n(structured.json)" --> Client
    end

    subgraph "Docker Compose: pdf-extraction-service"
        subgraph "labelstudio Service (Optional)"
            LabelStudio("üåê Label Studio\n(http://localhost:8080)") -- "Import Tasks" --> CorrectionsStorage
            LabelStudio -- "Export Annotations" --> Client
        end

        subgraph "fastapi Service"
            FastAPI("üöÄ FastAPI - api.py\n(http://localhost:8000)") -- "Extraction" --> Converter("üìÑ PDF Converter\npdf_converter.py")
            FastAPI -- "Write Output" --> OutputStorage
            FastAPI -- "Read Corrections" --> CorrectionsStorage
            Converter -- "Read PDFs" --> UploadsStorage
            Converter -- "Read/Write Corrections" --> CorrectionsStorage
            Converter -- "Camelot Extraction" --> CamelotLib("üìä Camelot")
            Converter -- "Marker Extraction" --> MarkerLib("üìù Marker")
            Converter -- "Qwen-VL-2B OCR" --> QwenLib("ü§ñ Qwen-VL-2B")
            Converter -- "Store Documents" --> ArangoDB("üóÑÔ∏è ArangoDB")
        end

        subgraph "Local Deployment"
            CLI("üíª Typer CLI - cli.py") -- "Extraction" --> Converter
        end

        subgraph "Storage Volumes"
            UploadsStorage{{üíæ uploads\n(PDF files)}}
            OutputStorage{{üíæ output\n(structured.json)}}
            CorrectionsStorage{{üíæ corrections\n(corrections JSON)}}
            LabelStudioData{{üíæ label-studio-data\n(project data)}}
        end
    end
```

**Diagram Key**: The diagram shows client interactions with the FastAPI server (1-6) for PDF conversion and streaming, and the Typer CLI (7-8) for local conversion. The FastAPI service uses `pdf_converter.py` to call Camelot, Marker, and Qwen-VL-2B. Shared volumes (`uploads`, `output`, `corrections`) ensure data persistence. Label Studio is optional for HITL validation.

## üõ†Ô∏è Technology Stack

- **Web Framework**: FastAPI (API orchestration, SSE support)
- **CLI Framework**: Typer (local deployment)
- **PDF Table Extraction**: Camelot (text-based PDFs)
- **Markdown Extraction**: Marker (structured content)
- **OCR and Scanned PDFs**: Qwen-VL-2B (via Transformers)
- **Annotation Platform**: Label Studio (optional HITL validation)
- **Database**: ArangoDB (document storage and querying)
- **PDF Processing**: `pdf2image`, `PyMuPDF` (fitz)
- **Text Normalization**: `cleantext`
- **Fuzzy Matching**: `fuzzywuzzy` (table merging)
- **Token Counting**: `tiktoken`
- **Logging**: `loguru`
- **Image Processing**: Pillow, OpenCV
- **Containerization**: Docker, Docker Compose
- **Dependency Management**: pip
- **SSE Support**: `sse-starlette` (for MCP compatibility)

## ü§ñ Agentic Workflow

This project is designed for agentic development, where AI agents collaborate to build, test, and maintain the codebase:

- **Planner**: Defines project goals (e.g., HITL workflow, SSE streaming), creates tasks, and assigns them to specialized agents.
- **Coder Agents**: Implement features (e.g., `pdf_converter.py`, `api.py`, `cli.py`), with levels (Intern, Junior, Senior) handling tasks of increasing complexity.
- **Debugger**: Identifies and fixes issues in extraction or API logic, using logs from `loguru`.
- **Documenter**: Updates `README.md`, ensuring feature descriptions, setup instructions, and usage examples are accurate.
- **Tester**: Designs and runs tests for extraction accuracy and API/CLI functionality.

Rules and prompts for agent behavior are defined in `.roorules` (not included in this setup but recommended for agentic workflows).

## üìÅ Project Structure

```
pdf-extraction-service/
‚îú‚îÄ‚îÄ .git/
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .env.example        # Example environment variables
‚îú‚îÄ‚îÄ docker-compose.yml  # Docker Compose service definition
‚îú‚îÄ‚îÄ Dockerfile          # FastAPI image build instructions
‚îú‚îÄ‚îÄ requirements.txt    # Python dependencies
‚îú‚îÄ‚îÄ README.md           # This file
‚îú‚îÄ‚îÄ api.py              # FastAPI server for PDF processing
‚îú‚îÄ‚îÄ cli.py              # Typer CLI for local PDF conversion
‚îú‚îÄ‚îÄ config.py           # Configuration settings
‚îú‚îÄ‚îÄ utils.py            # Utility functions
‚îú‚îÄ‚îÄ table_extraction.py # Table extraction logic
‚îú‚îÄ‚îÄ marker_processor.py # Marker-based processing
‚îú‚îÄ‚îÄ qwen_processor.py   # Qwen-VL-2B processing
‚îú‚îÄ‚îÄ pdf_converter.py    # Core PDF-to-JSON extraction logic
‚îú‚îÄ‚îÄ labeling_config.xml # Label Studio labeling interface (optional)
‚îú‚îÄ‚îÄ uploads/            # Volume for uploaded PDFs
‚îú‚îÄ‚îÄ output/             # Volume for structured.json output
‚îú‚îÄ‚îÄ corrections/        # Volume for corrections JSON
‚îú‚îÄ‚îÄ label-studio-data/  # Volume for Label Studio project data
‚îú‚îÄ‚îÄ _archive/           # Legacy scripts (e.g., pdf_to_json_converter.py)
```

**Volumes**:
- `uploads/`: Stores uploaded PDFs (`uploads/<pdf_id>.pdf`).
- `output/`: Stores final output (`output/<pdf_id>_structured.json`).
- `corrections/`: Stores corrections (`corrections/<pdf_id>_corrections.json`).
- `label-studio-data/`: Persists Label Studio project data.

## ‚öôÔ∏è Configuration

Configuration is managed via environment variables or defaults in `config.py`. Key settings include:

**FastAPI Server**:
- `OUTPUT_DIR`: Directory for outputs (`/app/output`).
- `CORRECTIONS_DIR`: Directory for corrections (`/app/corrections`).

**Label Studio (Optional)**:
- `LABEL_STUDIO_LOCAL_FILES_SERVING_ENABLED`: Enables local file serving (`true`).
- `LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT`: Sets corrections directory (`/app/corrections`).

Set environment variables in `.env` (copy from `.env.example`):
```bash
# FastAPI
OUTPUT_DIR=/app/output
CORRECTIONS_DIR=/app/corrections

# Label Studio
LABEL_STUDIO_LOCAL_FILES_SERVING_ENABLED=true
LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT=/app/corrections
```

## üõ†Ô∏è Setup & Installation

### Prerequisites
- Docker & Docker Compose ([Install Docker](https://docs.docker.com/get-docker/))
- Git (for cloning the repository)
- Python 3.10+ (for local CLI usage)
- ArangoDB (for document storage)
- 256GB RAM and 24GB GPU (for optimal performance)

### Steps
1. **Clone the Repository**:
   ```bash
   git clone <repository_url>
   cd pdf-extraction-service
   ```

2. **(Optional) Configure Environment**:
   Copy `.env.example` to `.env` and adjust variables if needed:
   ```bash
   cp .env.example .env
   ```

3. **Prepare Files**:
   Ensure `Dockerfile`, `docker-compose.yml`, `requirements.txt`, `api.py`, `cli.py`, `pdf_converter.py`, and other refactored scripts are in the project root.

## üöÄ Running the Service

### Dockerized FastAPI Server
Run the service using Docker Compose:
```bash
docker compose up --build -d
```

This will:
- Build the `fastapi` image using `Dockerfile`.
- Start the `labelstudio` service (`heartexlabs/label-studio:latest`, optional).
- Start the `fastapi` service (`api.py` and `pdf_converter.py`).
- Create/use named volumes (`uploads`, `output`, `corrections`, `label-studio-data`).

Services are available at:
- **FastAPI**: `http://localhost:8000` (Swagger UI: `http://localhost:8000/docs`)
- **Label Studio**: `http://localhost:8080` (if enabled)

View logs:
```bash
docker compose logs -f
```

Stop services:
```bash
docker compose down
```

### Local CLI
Run the Typer CLI for local PDF conversion:
```bash
python cli.py convert sample.pdf --repo-link https://github.com/example/repo
```

Output: `output/sample_structured.json`

## üíª API Usage

Interact with the FastAPI server via HTTP endpoints:

### POST `/convert`
- **Request**: Form data with `file` (PDF), `repo_link`, `use_marker_markdown`, `force_qwen`, `output_dir`, `corrections_dir`.
- **Response**: JSON with extracted data.
- **Example**:
  ```bash
  curl -X POST "http://localhost:8000/convert" \
       -F "file=@sample.pdf" \
       -F "repo_link=https://github.com/example/repo"
  ```
  **Response**:
  ```json
  {
    "status": "success",
    "message": "PDF converted successfully.",
    "data": [
      {
        "type": "heading",
        "level": 1,
        "text": "Introduction",
        "token_count": 1,
        "file_path": "sample.pdf",
        "repo_link": "https://github.com/example/repo",
        "extraction_date": "2025-04-19T12:00:00.000000",
        "source": "marker_json"
      }
    ]
  }
  ```

### POST `/stream/convert`
- **Request**: Same as `/convert`, streams progress via SSE.
- **Response**: SSE events (start, progress, complete, error).
- **Example**:
  ```bash
  curl http://localhost:8000/stream/convert \
       -F "file=@sample.pdf" \
       -F "repo_link=https://github.com/example/repo"
  ```
  **Response** (streamed):
  ```
  event: start
  data: {"message": "Starting conversion for sample.pdf"}

  event: progress
  data: {"elements_extracted": 5}

  event: complete
  data: {"message": "Conversion complete", "data": [...]}
  ```

### GET `/status`
- **Response**: JSON with server status.
- **Example**:
  ```bash
  curl http://localhost:8000/status
  ```
  **Response**:
  ```json
  {
    "status": "success",
    "message": "PDF to JSON Converter API is running."
  }
  ```

## ü§î Key Concepts Explained

- **pdf_id**: Unique identifier for a PDF (derived from filename, e.g., `sample` for `sample.pdf`).
- **Structured JSON Output**: Hierarchical JSON (`structured.json`) with tables, headings, and paragraphs, including metadata (`page_range`, `source`).
- **SSE Streaming**: Server-Sent Events stream conversion progress, supporting real-time updates in MCP architectures.
- **Corrections JSON**: File (`corrections/<pdf_id>_corrections.json`) for storing human validations (requires additional endpoints).
- **Label Studio Tasks**: JSON files (`corrections/<pdf_id>_tasks.json`) for human review (requires additional endpoints).
- **Section Hierarchy**: Maintains parent-child relationships between document sections for structured output.
- **ArangoDB Integration**: Stores and enables semantic, BM25, keyword, and hybrid queries of extracted content.

## üß™ Testing

### Manual Testing
- **API**: Upload a PDF via `/convert`, verify `structured.json` in `output/`, and test streaming with `/stream/convert`.
- **CLI**: Run `python cli.py convert sample.pdf` and verify output.
- **Label Studio** (if enabled): Import tasks, validate tables, and export corrections.

### Unit Tests (Recommended)
- Add tests for `pdf_converter.py` functions (e.g., table extraction, merging).
- Use `pytest` to test FastAPI endpoints (`api.py`) and CLI commands (`cli.py`).

### Integration Tests
- Test end-to-end flow: PDF upload ‚Üí conversion ‚Üí output verification.
- **Example**:
  ```bash
  # API
  curl -X POST "http://localhost:8000/convert" -F "file=@test.pdf" -F "repo_link=https://github.com/example/repo"
  # CLI
  python cli.py convert test.pdf --repo_link https://github.com/example/repo
  ```

### Test Cases
- **Complex PDF**: Verify tables, headings, and paragraphs in `structured.json`.
- **Scanned PDF**: Ensure Qwen-VL-2B extracts content correctly.
- **Streaming**: Confirm SSE events are received during `/stream/convert`.

## üìö Documentation Standards

- **Module Docstrings**: Each `.py` file includes a docstring with purpose, third-party links, and sample input/output.
- **Standalone Verification**: `pdf_converter.py`, `api.py`, and `cli.py` include `if __name__ == "__main__":` blocks for testing.
- **Code Comments**: Inline comments explain complex logic (e.g., extraction algorithms).
- **README Accuracy**: This file documents features, setup, API/CLI usage, and concepts, updated with project changes.
- **Lessons Learned**: Store insights (e.g., handling scanned PDFs) in a future `docs/lessons_learned.json`.

## üöß Future Improvements

- Add Label Studio integration to `api.py` for task generation and corrections.
- Implement unit and integration tests for robust validation.
- Develop a frontend for easier PDF uploads and management.
- Support additional extraction methods (e.g., advanced OCR models).
- Add authentication to FastAPI for secure access.
